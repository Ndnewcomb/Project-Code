{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: Number of epochs with no improvement after which training will be stopped.\n",
    "        :param min_delta: Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold standard with report and center cropping\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, ToTensord, RandRotate90d, CenterSpatialCropd\n",
    ")\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.losses import DiceLoss\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.handlers import StatsHandler, TensorBoardImageHandler\n",
    "from monai.utils import set_determinism\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Set determinism for reproducibility\n",
    "set_determinism(seed=0)\n",
    "\n",
    "# MONAI's transforms for dictionary format use 'd' at the end\n",
    "# Assuming EnsureChannelFirstd is a valid replacement for AddChannel\n",
    "print(\"Setting up directories and initial configurations...\")\n",
    "\n",
    "\n",
    "def create_dataset(data_dir):\n",
    "    data_dicts = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\"_Vx3.nrrd\"):  # Identifies the image files\n",
    "            image_path = os.path.join(data_dir, filename)\n",
    "            label_filename = filename.replace(\"_Vx3.nrrd\", \"_Label.nrrd\")  # Creates the label filename\n",
    "            label_path = os.path.join(data_dir, label_filename)\n",
    "            data_dicts.append({'image': image_path, 'label': label_path})\n",
    "    return data_dicts\n",
    "\n",
    "# Set the paths for the training and validation data directories\n",
    "train_data_dir = \"z:/W-People/Nate/Deep_Learning_Data/Train\"\n",
    "val_data_dir = \"z:/W-People/Nate/Deep_Learning_Data/Validation\"\n",
    "\n",
    "# Desired sizes for cropping (not used in create_dataset but may be used elsewhere)\n",
    "desired_height, desired_width, desired_depth = 128, 128, 128 \n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "train_files = create_dataset(train_data_dir)  # Only get files from the \"Train\" folder\n",
    "val_files = create_dataset(val_data_dir)  \n",
    "\n",
    "# Data Transformations\n",
    "print(\"Defining transformations...\")\n",
    "roi_size = (desired_depth, desired_height, desired_width)  # Define the size of the cropped region\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    CenterSpatialCropd(keys=['image', 'label'], roi_size=roi_size), # Use random cropping\n",
    "    RandRotate90d(keys=['image', 'label'], prob=0.5),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "]) \n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    CenterSpatialCropd(keys=['image', 'label'], roi_size=roi_size),  # Use random cropping for validation as well\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "]) \n",
    "\n",
    "train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True) #collate_fn=pad_list_data_collate\n",
    "val_loader = DataLoader(val_ds, batch_size=1) # collate_fn=pad_list_data_collate\n",
    "\n",
    "# UNet Model Initialization\n",
    "\n",
    "print(\"Initializing 3D U-Net model...\")\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=3,  # This specifies that the network should be 3D\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2)\n",
    ")\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True) #to_onehot_y=True,\n",
    "optimizer = Adam(model.parameters(), 1e-3) # This is the learning rate \n",
    "model_save_path = \"z:/W-People/Nate/Deep_Learning_Data/Deep Learning Model/Nate_Unet.pth\"\n",
    "optimizer_save_path = \"z:/W-People/Nate/Deep_Learning_Data/Deep Learning Model/Nate_Unet_optimzer.pth\"\n",
    "# Load the state dict into the model\n",
    "\n",
    "if os.path.exists(model_save_path) and os.path.exists(optimizer_save_path):\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    optimizer.load_state_dict(torch.load(optimizer_save_path))\n",
    "    print(\"Loaded saved model and optimizer.\")\n",
    "else:\n",
    "    print(\"No saved model or optimizer state found. Starting from scratch.\")\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training and Validation Functions\n",
    "def train_epoch(model, loader, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_data in loader:\n",
    "        inputs, targets = batch_data['image'], batch_data['label']\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "\n",
    "def validate_epoch(model, loader, loss_function, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data in loader:\n",
    "            inputs, targets = batch_data['image'], batch_data['label']\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "# Main Training Loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20, min_delta=0.001)  # You can adjust these parameters\n",
    "\n",
    "\n",
    "print(\"Starting training process...\")\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, loss_function, device)\n",
    "    val_loss = validate_epoch(model, val_loader, loss_function, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "   \n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "torch.save(optimizer.state_dict(), optimizer_save_path)\n",
    "print(f\"Model and optimizer states saved to {model_save_path} and {optimizer_save_path} respectively.\")\n",
    "\n",
    "\n",
    "# Plotting loss curves\n",
    "print(\"Plotting loss curves...\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def visualize_predictions(loader, model, device, num_images=3, slice_index=32):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(loader))\n",
    "        inputs, targets = batch['image'], batch['label']\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Convert model output to binary predictions\n",
    "        predicted_labels = outputs.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        for i in range(min(num_images, len(inputs))):\n",
    "            plt.figure(figsize=(18, 6))\n",
    "\n",
    "            # Selecting a slice to display\n",
    "            input_slice = np.squeeze(inputs[i].cpu()[0, slice_index, :, :])\n",
    "            target_slice = np.squeeze(targets[i].cpu()[0, slice_index, :, :])\n",
    "            predicted_slice = np.squeeze(predicted_labels[i].cpu()[0, slice_index, :, :])\n",
    "\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(input_slice, cmap='gray')\n",
    "            plt.title('Original Image Slice')\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(target_slice, cmap='gray')\n",
    "            plt.title('True Label Slice')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(predicted_slice, cmap='gray')\n",
    "            plt.title('Predicted Label Slice')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "visualize_predictions(val_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_predictions(batch, predictions, alpha=0.3, num_images=3, slice_index=32):\n",
    "    images, labels = batch['image'], batch['label']\n",
    "    for i in range(min(num_images, len(images))):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "\n",
    "        # Selecting a slice to display\n",
    "        image_slice = np.squeeze(images[i][0, slice_index, :, :])\n",
    "        prediction_slice = np.squeeze(predictions[i][0, slice_index, :, :])\n",
    "\n",
    "        plt.imshow(image_slice, cmap='gray')\n",
    "        plt.imshow(prediction_slice, cmap='winter', alpha=alpha)\n",
    "        plt.title('Overlay of Prediction on Original Image Slice')\n",
    "        plt.show()\n",
    "\n",
    "# Create overlay visualizations\n",
    "batch_data = next(iter(val_loader))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = batch_data['image'].to(device)\n",
    "    outputs = model(inputs)\n",
    "    predicted_labels = outputs.argmax(dim=1, keepdim=True).cpu()\n",
    "    overlay_predictions(batch_data, predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mayavi import mlab\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_3d(loader, model, device, num_volumes=1):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(loader))\n",
    "        inputs, targets = batch['image'], batch['label']\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Convert model output to binary predictions\n",
    "        predicted_labels = outputs.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        for i in range(min(num_volumes, len(inputs))):\n",
    "            # Reconstruct 3D volumes\n",
    "            input_volume = inputs[i].cpu().squeeze().numpy()\n",
    "            target_volume = targets[i].cpu().squeeze().numpy()\n",
    "            predicted_volume = predicted_labels[i].cpu().squeeze().numpy()\n",
    "\n",
    "            # Set up a figure\n",
    "            fig = mlab.figure(size=(800, 800), bgcolor = (0,0,0))\n",
    "\n",
    "            # Visualize original image volume\n",
    "            #mlab.contour3d(input_volume, contours=[input_volume.max()/2], color=(0, 0, 1), transparent=True, figure=fig)\n",
    "\n",
    "            # Visualize true label volume\n",
    "            mlab.contour3d(target_volume, contours=[target_volume.max()/2], color=(0, 1, 0), transparent=True, figure=fig)\n",
    "\n",
    "            # Visualize predicted label volume\n",
    "            # mlab.contour3d(predicted_volume, contours=[predicted_volume.max()/2], color=(1, 0, 0), transparent=True, figure=fig)\n",
    "\n",
    "            # Display the visualization\n",
    "            mlab.show()\n",
    "\n",
    "# Call the function with appropriate parameters\n",
    "visualize_predictions_3d(val_loader, model, device)\n",
    "\n",
    "\n",
    "\n",
    "# Problems to be fixed\n",
    "# input volume should be ct image,,, when showing that in mayavi WHAT ARE YOU ACTUALLY SHOWING?\n",
    "# do use contour 3d\n",
    "# Add early stopping make epochs 200 \n",
    "# first experiment add 5 images in validation train with two images\n",
    "# try to get the best thing we can get just from two images first\n",
    "# use the exact same 5 for validation\n",
    "# ask chat gpt for creating a report (capabilities in monai)\n",
    "# Change learning rate maybe add adaptive learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mayavi import mlab\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_3d(loader, model, device, num_volumes=1):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(loader))\n",
    "        inputs, targets = batch['image'], batch['label']\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Convert model output to binary predictions\n",
    "        predicted_labels = outputs.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        for i in range(min(num_volumes, len(inputs))):\n",
    "            # Reconstruct 3D volumes\n",
    "            input_volume = inputs[i].cpu().squeeze().numpy()\n",
    "            target_volume = targets[i].cpu().squeeze().numpy()\n",
    "            predicted_volume = predicted_labels[i].cpu().squeeze().numpy()\n",
    "\n",
    "            # Set up a figure\n",
    "            fig = mlab.figure(size=(800, 800), bgcolor=(0, 0, 0))\n",
    "\n",
    "            # Visualize true label volume\n",
    "            target_src = mlab.pipeline.scalar_field(target_volume)\n",
    "            mlab.pipeline.iso_surface(target_src, contours=[target_volume.max() * 0.5], \n",
    "                                      colormap='winter', opacity=.5, figure=fig)\n",
    "\n",
    "            # Visualize predicted label volume\n",
    "            predicted_src = mlab.pipeline.scalar_field(predicted_volume)\n",
    "            mlab.pipeline.iso_surface(predicted_src, contours=[predicted_volume.max() * 0.5], \n",
    "                                      colormap='rainbow', opacity=1, figure=fig)\n",
    "\n",
    "            # Add legends and annotations\n",
    "            mlab.text(0.01, 0.01, \"Target Volume\", color=(0, 0, 1), width=0.15, figure=fig)\n",
    "            mlab.text(0.01, 0.95, \"Predicted Volume\", color=(1, 0, 0), width=0.15, figure=fig)\n",
    "\n",
    "            # Display the visualization\n",
    "            mlab.show()\n",
    "\n",
    "# Assuming val_loader, model, and device have been defined elsewhere in your script:\n",
    "visualize_predictions_3d(val_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mayavi import mlab\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_3d(loader, model, device, num_volumes=1):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(loader))\n",
    "        inputs, targets = batch['image'], batch['label']\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Convert model output to binary predictions\n",
    "        predicted_labels = outputs.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        for i in range(min(num_volumes, len(inputs))):\n",
    "            # Reconstruct 3D volumes\n",
    "            input_volume = inputs[i].cpu().squeeze().numpy()\n",
    "            target_volume = targets[i].cpu().squeeze().numpy()\n",
    "            predicted_volume = predicted_labels[i].cpu().squeeze().numpy()\n",
    "\n",
    "            target_volume = target_volume.astype(np.float32)\n",
    "            predicted_volume = predicted_volume.astype(np.float32)\n",
    "\n",
    "            # Set up a figure\n",
    "            fig = mlab.figure(size=(800, 800), bgcolor=(0, 0, 0))\n",
    "\n",
    "            # Visualize original image volume\n",
    "            # For better visualization, you may want to preprocess your volume\n",
    "            # to set a threshold or adjust intensities.\n",
    "            # input_volume_processed = preprocess_volume(input_volume)\n",
    "            # mlab.pipeline.volume(mlab.pipeline.scalar_field(input_volume_processed), figure=fig)\n",
    "\n",
    "            # Visualize true label volume\n",
    "            true_volume_src = mlab.pipeline.scalar_field(target_volume)\n",
    "            mlab.pipeline.volume(true_volume_src, vmin=0, vmax=target_volume.max(), figure=fig)\n",
    "\n",
    "            # Visualize predicted label volume\n",
    "            predicted_volume_src = mlab.pipeline.scalar_field(predicted_volume)\n",
    "            mlab.pipeline.volume(predicted_volume_src, vmin=0, vmax=predicted_volume.max(), figure=fig)\n",
    "\n",
    "            # Display the visualization\n",
    "            mlab.show()\n",
    "\n",
    "# Call the function with appropriate parameters\n",
    "visualize_predictions_3d(val_loader, model, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
